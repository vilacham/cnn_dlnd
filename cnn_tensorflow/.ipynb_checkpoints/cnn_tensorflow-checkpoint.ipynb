{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs no TensorFlow\n",
    "\n",
    "Neste notebook, vamos examinar como implementar uma rede neural convolucional no TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Camadas convolucionais no TensorFlow\n",
    "\n",
    "Nesta seção, vamos examinar como implementar uma camada convolucional no TensorFlow.\n",
    "\n",
    "O TensorFlow fornece as funções [**`tf.nn.conv2d()`**](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d), [**`tf.nn.bias_add()`**](https://www.tensorflow.org/api_docs/python/tf/nn/bias_add) e [**`tf.nn.relu()`**](https://www.tensorflow.org/api_docs/python/tf/nn/relu) para que você possa criar suas próprias camadas convolucionais:\n",
    "\n",
    "```\n",
    "# Profundidade do output\n",
    "k_output = 64\n",
    "\n",
    "# Dimensões da imagem\n",
    "img_width = 10\n",
    "img_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Filtro de convolução\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Peso e viés\n",
    "weight = tf.Variable(tf.truncated_normal([filter_size_height, \n",
    "                                          filter_size_width, \n",
    "                                          color_channels, \n",
    "                                          k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Aplicar convolução, adicionar viés e aplicar função de ativação\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], \n",
    "                          padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código acima usa a função [**`tf.nn.conv2d()`**](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) para computar a convolução usando `weight` como filtro e `[1, 2, 2, 1]` como passo.\n",
    "\n",
    "É importante ressaltar que:\n",
    "\n",
    "* O TensorFlow usa um passo para cada dimensão de entrada (`input`): `[batch, input_height, input_width, input_channels]`.\n",
    "* Em geral, configuramos o passo para `batch` e `input_channels` (ou seja, o primeiro e quarto elementos do array `strides`) como `1`. Isso assegura que o modelo usa todos lotes e canais de entrada (*é uma boa prática remover do conjunto de dados lotes ou canais que você queira pular, em vez de usar o passo para pulá-los*).\n",
    "* Você irá se concentrar em alterar `input_height` e `input_width` (mantendo `batch` e `input_channels` em 1). Os passos `input_height` e `input_width` servem para configurar a movimentação do filtro sobre a entrada `input`. O código exemplo usa um passo de 2 com um filtro 5x5 sobre `input`. Observe que o passo foi considerado um só número pois é simétrico, ou seja, `height = width`; quando alguém diz que está usando um passo de 2, isso significa que usou algo como `tf.nn.conv2d(x, W, stride=[1, 2, 2, 1])`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função [**`tf.nn.bias_add()`**](https://www.tensorflow.org/api_docs/python/tf/nn/bias_add) adiciona um viés unidimensional à última dimensão da matriz (observe que usar [**`tf.add`**](https://www.tensorflow.org/api_docs/python/tf/add) não funciona quando os tensores não são do mesmo formato)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função [**`tf.nn.relu()`**](https://www.tensorflow.org/api_docs/python/tf/nn/relu) aplica uma função de ativação ReLu à camada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando camadas convolucionais no TensorFlow\n",
    "\n",
    "Agora vamos construir uma camada convolucional no TensorFlow. Na célula abaixo, será solicitado que você configure as dimensões dos filtros de convolução, bem como os pesos e vieses. Esta é, de diversas formas, a parte mais complicada de se usar CNNs no TensorFlow. Quando você tiver uma noção de como configurar as dimensões destes atributos, usar CNNs será muito mais direto ao ponto.\n",
    "\n",
    "Recomendamos que você reveja a documentação do TensorFlow para [**convoluções 2D**](https://www.tensorflow.org/api_guides/python/nn#Convolution). A maior parte da documentação é bem direta, exceto talvez a explicação do argumento `padding` (espaçamento), que pode variar dependendo de você paassar `'VALID'` ou `'SAME'`. Além disso, recomendamos que também revise sobre [**variáveis no TensorFlow**](https://www.tensorflow.org/programmers_guide/variables) e sobre como determinar as dimensões da saída baseado no tamanho da entrada e do filtro (você usará isso para determinar o tamanho que seu filtro deve ter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.nn.conv2d requer que o input seja 4D (batch_size, height, width, \n",
    "# depth)\n",
    "x = np.array([[0, 1, 0.5, 10], \n",
    "              [2, 2.5, 1, -8], \n",
    "              [4, 0, 5, 6], \n",
    "              [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "# Configure strides, padding, pesos e vieses de modo que o formato da\n",
    "# saída seja (1, 2, 2, 3)\n",
    "def conv2d(input_tensor):\n",
    "    # TODO: Definir os filtros weight e bias\n",
    "    # O formato de weight é (height, width, input_depth, output_depth)\n",
    "    F_W = tf.Variable(tf.truncated_normal((2, 2, 1, 3)))\n",
    "    # O formato de bias é (output_depth,)\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "\n",
    "    \n",
    "    # TODO: Configurar stride para cada dimensão (batch_size, height, \n",
    "    # width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    \n",
    "    # TODO: configurar padding como 'VALID' ou 'SAME'\n",
    "    padding = 'VALID'\n",
    "    \n",
    "    # Como tf.nn.conv2d() não inclui bias, este deve ser adicionado\n",
    "    # manualmente\n",
    "    no_bias = tf.nn.conv2d(input_tensor, F_W, strides, padding)\n",
    "    output = tf.nn.bias_add(no_bias, F_b)\n",
    "    return output\n",
    "\n",
    "output_tensor = conv2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Camadas maxpooling no TensorFlow\n",
    "\n",
    "Conceitualmente, o benefício da operação de [agrupamento máximo](https://en.wikipedia.org/wiki/Convolutional_neural_network#Pooling_layer) é a redução do tamanho de entrada, permitindo ue a rede neural se concentre apenas nos elementos mais importantes. O agrupamento máximo faz isso retendo apenas o valor máximo para cada área filtrada, e removendo os valores remanescentes.\n",
    "\n",
    "O TensorFlow fornece a função [**`tf.nn.max_pool()`**](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) para aplicar a operação de agrupamento máximo às suas camadas convolucionais.\n",
    "\n",
    "```\n",
    "# Aplicar maxpooling\n",
    "conv_layer = tf.nn.max_pool(conv_layer, \n",
    "                            ksize=[1, 2, 2, 1], \n",
    "                            strides=[1, 2, 2, 1], \n",
    "                            padding='SAME')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A função [**`tf.nn.max_pool()`**](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) aplica o agrupamento máximo com o parâmetro `ksize` como tamanho do filtro e o parâmetro `strides` como o tamanho do passo. Filtros 2x2 com um passo 2x2 são comuns, na prática.\n",
    "\n",
    "Esses dois parâmetros, `ksize` e `strides`, são estruturados como listas de quatro elementos, cada um correspondente à uma dimensão do tensor de entrada(`[batch, height, width, channels]`). Para ambos, as dimensões `batch` e `channels` são tipicamente configuradas como `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando camadas maxpooling no TensorFlow\n",
    "\n",
    "Na célula abaixo, será solicitado que você configure as dimensões dos filtros de agrupamento, passos e espaçamento. \n",
    "\n",
    "Recomendamos que faça a leitura da documentação do TensorFlow para [**`tf.nn.max_pool()`**](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool). Note que o espaçamento (padding) funciona da mesma forma como na convolução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# tf.nn.max_pool requer que o input seja 4D (batch_size, height, width, \n",
    "# depth)\n",
    "x = np.array([[0, 1, 0.5, 10], \n",
    "              [2, 2.5, 1, -8], \n",
    "              [4, 0, 5, 6], \n",
    "              [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "# Configure strides, padding e ksize de modo que o formato da saída \n",
    "# seja (1, 2, 2, 1)\n",
    "def maxpool(input_tensor):\n",
    "    # TODO: Definir o filtro ksize\n",
    "    # O formato de ksize é (height, width, input_depth, output_depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    \n",
    "    # TODO: Configurar stride para cada dimensão (batch_size, height, \n",
    "    # width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    \n",
    "    # TODO: configurar padding como 'VALID' ou 'SAME'\n",
    "    padding = 'VALID'\n",
    "    \n",
    "    output = tf.nn.max_pool(input_tensor, ksize, strides, padding)\n",
    "    return output\n",
    "\n",
    "output_tensor = maxpool(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Redes neurais convolucionais no TensorFlow\n",
    "\n",
    "Agora é hora de mostrarmos um exemplo passo a passo de rede neural convolucional no TensorFlow. A estrutura do código que vamos usar segue uma estrutura clássica de CNNs, que é uma mistura de camadas convolucionais de agrupamento máximo, seguidas por camadas completamente conectadas. O código pe similar ao que vimos [neste notebook](https://github.com/vilacham/tensorflow_introduction/blob/master/redes_neurais_profundas.ipynb), exceto pelo fato de que reestruturamos a arquitetura da rede como uma CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O conjunto de dados\n",
    "\n",
    "Já vimos esta seção de código. Aqui, vamos importar o conjunto de dados do MNIST e usar uma função conveniente do TensorFlow para organizá-lo em lotes, escalar e aplicar a codificação one-hot aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo hiperparâmetros\n",
    "\n",
    "Aqui, vamos configurar os hiperparâmetros da CNN: taxa de aprendizado, número de épocas, tamanho dos lotes, quantidade de classes, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001    # Taxa de aprendizado\n",
    "epochs = 100               # Número de épocas\n",
    "batch_size = 128           # Tamanho dos lotes\n",
    "test_valid_size = 256      # Número de amostras para calcular validação e acurácia\n",
    "n_classes = 10             # Quantidade de classes\n",
    "dropout = 0.75             # Probabilidade de manter as unidades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pesos e vieses\n",
    "\n",
    "Abaixo, serão criadas listas para armazenar os pesos e vieses. Nossa CNN contará com duas camadas alternando entre convoluções e agrupamento máximo, seguidas por uma camada completamente conectada e uma camada de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "weights = {'w_conv1': tf.Variable(tf.random_normal([5, 5, 1, 32])), \n",
    "           'w_conv2': tf.Variable(tf.random_normal([5, 5, 32, 64])), \n",
    "           'w_fc': tf.Variable(tf.random_normal([7*7*64, 1024])), \n",
    "           'w_out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {'b_conv1': tf.Variable(tf.random_normal([32])), \n",
    "          'b_conv2': tf.Variable(tf.random_normal([64])), \n",
    "          'b_fc': tf.Variable(tf.random_normal([1024])), \n",
    "          'b_out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camadas convolucionais\n",
    "\n",
    "Usaremos as funções [**`tf.nn.conv2d()`**](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d), [**`tf.nn.bias_add()`**](https://www.tensorflow.org/api_docs/python/tf/nn/bias_add) e [**`tf.add`**](https://www.tensorflow.org/api_docs/python/tf/add) para definir uma função que computa a convolução usando pesos e adicionando o viés, e em seguida aplica uma função de ativação ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], \n",
    "                     padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camadas de maxpooling\n",
    "\n",
    "Usaremos a função [**`tf.nn.max_pool()`**](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool) para dfinir uma função que aplica o agrupamento máximo a cada camada `x` usando um filtro de tamanho `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], \n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo\n",
    "\n",
    "Na célula abaixo vamos definir uma função que cria o nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Camada 1 (convolucional + maxpooling) - 28x28x1 para 14x14x32\n",
    "    conv1 = conv2d(x, weights['w_conv1'], biases['b_conv1'])\n",
    "    conv2 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    # Camada 2 (convolucional + maxpooling) - 14x14x32 para 7x7x64\n",
    "    conv2 = conv2d(conv1, weights['w_conv2'], biases['b_conv2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # Camada 3 (completamente conectada) - 7x7x64 para 1032\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['w_fc'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['w_fc']), biases['b_fc'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Camada de saída (previsão de cada classe)\n",
    "    output = tf.add(tf.matmul(fc1, weights['w_out']), biases['b_out'])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento\n",
    "\n",
    "Agora vamos treinar nossa CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafo\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Modelo\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Função de custo e otimizador\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "optmizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Acurácia\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Inicializador de variáveis\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Iniciar sessão\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optmizer, feed_dict={x: batch_x, \n",
    "                                          y: batch_y, \n",
    "                                          keep_prob: dropout})\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, \n",
    "                                             y: batch_y, \n",
    "                                             keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={x: mnist.validation.images[:test_valid_size], \n",
    "                                                      y: mnist.validation.labels[:test_valid_size], \n",
    "                                                      keep_prob: 1.})\n",
    "            print('Epoch {:>2}, Batch {:>3}: Loss = {:>10.4f} | Validation accuracy = {:.6f}'.format(epoch + 1, batch + 1, loss, valid_acc))\n",
    "\n",
    "    # Calcular acurácia no conjunto de teste\n",
    "    test_acc = sess.run(accuracy, feed_dict={x: mnist.test.images[:test_valid_size], \n",
    "                                             y: mnist.test.labels[:test_valid_size], \n",
    "                                             keep_prob: 1.})\n",
    "    print('Test accuracy: {:.6f}'.format(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
